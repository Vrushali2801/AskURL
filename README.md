# ğŸ”— AskURL - Ask Questions About Web Content

A Streamlit web application that lets you load content from multiple URLs and ask questions using AI-powered retrieval-augmented generation (RAG). Built with LangChain, GPT-4o, and FAISS vector search.

## âœ¨ Features

- **ğŸ”— Multi-URL Support**: Load and analyze content from multiple web pages simultaneously
- **ğŸ§  RAG-Based Q&A**: Get intelligent answers based on retrieved context from your sources
- **ğŸ“Š Source Citations**: Every answer shows which URLs it came from for transparency
- **ğŸ’¾ FAISS Persistence**: Automatically saves processed data - no need to reprocess
- **ğŸ’¬ Chat Interface**: Modern chat-style UI with conversation history
- **ğŸ—ï¸ Modular Design**: Clean code structure for easy customization

## ğŸš€ Quick Start

### Installation

```powershell
# Clone the repository
git clone https://github.com/Vrushali2801/AskURL.git
cd AskURL

# Create and activate virtual environment
python -m venv .venv
.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt
```

### Configuration

Create a `.env` file in the project root:

```env
GITHUB_TOKEN=your_github_token_here
```

Get your token from [GitHub Models](https://github.com/marketplace/models) or use your Azure OpenAI credentials.

### Run the Application

```powershell
streamlit run app.py
```

The app will open at `http://localhost:8501`

## ğŸ“– How to Use

### Processing URLs

1. **Enter URLs** in the sidebar text area (one per line)
2. **Click "Process URLs"** to load and analyze the content
   - Progress indicators show: Data Loading â†’ Text Splitting â†’ Embedding
3. **Ask questions** in the chat input
4. **View answers** with source URL citations

### Loading Saved Index

Already processed URLs before? Click **"Load Existing Index"** to instantly reload your previous data without reprocessing.

### Example Workflow

```
URLs to try:
https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-11351111.html
https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-11098751.html

Questions:
- "What is the main topic of these articles?"
- "What companies are mentioned?"
- "Summarize the key points"
```

## ğŸ› ï¸ Technologies

- **Streamlit** - Web interface with chat components
- **LangChain** - RAG framework and document processing
- **OpenAI GPT-4o** - Language model via Azure AI
- **FAISS** - Vector similarity search and storage
- **Unstructured** - URL content loading and parsing
- **Python-dotenv** - Environment variable management

## âš™ï¸ Configuration

Edit [config.py](config.py) to customize the application:

```python
# Model Settings
LLM_MODEL = "gpt-4o"                    # Language model
EMBEDDING_MODEL = "text-embedding-3-small"  # Embedding model
LLM_TEMPERATURE = 0                     # Response randomness (0 = deterministic)

# Text Processing
CHUNK_SIZE = 1000                       # Text chunk size for splitting
CHUNK_OVERLAP = 200                     # Overlap between chunks

# Retrieval
RETRIEVAL_K = 3                         # Number of documents to retrieve

# Storage
FAISS_INDEX_PATH = "faiss_store_openai.pkl"  # Vector store location
```

## ğŸ—ï¸ Project Structure

```
News-Search-Tool/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ config.py                   # Configuration settings
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Environment variables (create this)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_processor.py   # URL loading, text splitting, FAISS operations
â”‚   â””â”€â”€ qa_chain.py             # RAG chain with source attribution
â””â”€â”€ faiss_store_openai/         # Saved vector store (auto-generated)
    â”œâ”€â”€ index.faiss
    â””â”€â”€ index.pkl
```

### Module Overview

- **`document_processor.py`**: Handles loading URLs, splitting text into chunks, creating embeddings, and managing FAISS vector store persistence
- **`qa_chain.py`**: Manages the RAG chain for question-answering with source tracking and document retrieval
- **`config.py`**: Centralized configuration for models, API settings, and application parameters

## ğŸ’¡ How It Works

1. **Load**: URLs are fetched and content is extracted using UnstructuredURLLoader
2. **Split**: Documents are split into manageable chunks (1000 chars with 200 overlap)
3. **Embed**: Text chunks are converted to vector embeddings using OpenAI's embedding model
4. **Store**: Embeddings are stored in a FAISS vector database for fast similarity search
5. **Retrieve**: When you ask a question, the most relevant chunks are retrieved
6. **Generate**: GPT-4o generates an answer based on the retrieved context
7. **Cite**: Source URLs are tracked and displayed with each answer

## ğŸ¤ Contributing

Contributions are welcome! Feel free to fork the repository and submit pull requests.
